{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Reshape, Flatten, LeakyReLU, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import normal_latent_sampling, AdversarialOptimizerSimultaneous\n",
    "from keras_adversarial.legacy import l1l2, Dense, fit\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_process(x):\n",
    "    x = x.astype(np.float32) / 255.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def mnist_data():\n",
    "    (xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "    return mnist_process(xtrain), mnist_process(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator(latent_dim, input_shape, hidden_dim=1024, reg=lambda: l1l2(1e-5, 1e-5)):\n",
    "    return Sequential([\n",
    "        Dense(int(hidden_dim / 4), name=\"generator_h1\", input_dim=latent_dim, W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(int(hidden_dim / 2), name=\"generator_h2\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(hidden_dim, name=\"generator_h3\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(np.prod(input_shape), name=\"generator_x_flat\", W_regularizer=reg()),\n",
    "        Activation('sigmoid'),\n",
    "        Reshape(input_shape, name=\"generator_x\")],\n",
    "        name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator(input_shape, hidden_dim=1024, reg=lambda: l1l2(1e-5, 1e-5), output_activation=\"sigmoid\"):\n",
    "    return Sequential([\n",
    "        Flatten(name=\"discriminator_flatten\", input_shape=input_shape),\n",
    "        Dense(hidden_dim, name=\"discriminator_h1\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(int(hidden_dim / 2), name=\"discriminator_h2\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(int(hidden_dim / 4), name=\"discriminator_h3\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(1, name=\"discriminator_y\", W_regularizer=reg()),\n",
    "        Activation(output_activation)],\n",
    "        name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z \\in R^100\n",
    "latent_dim = 100\n",
    "\n",
    "# x \\in R^{28x28}\n",
    "input_shape = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_h1 (Dense)         (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "generator_h2 (Dense)         (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "generator_h3 (Dense)         (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "generator_x_flat (Dense)     (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "generator_x (Reshape)        (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 1,486,352.0\n",
      "Trainable params: 1,486,352.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generator (z -> x)\n",
    "generator = model_generator(latent_dim, input_shape)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_flatten (Flatt (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_h1 (Dense)     (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "discriminator_h2 (Dense)     (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_h3 (Dense)     (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_y (Dense)      (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,460,225.0\n",
      "Trainable params: 1,460,225.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# discriminator (x -> y)\n",
    "discriminator = model_discriminator(input_shape)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvpath = os.path.join(\"output/gan\", \"history.csv\")\n",
    "if os.path.exists(csvpath):\n",
    "    print(\"Already exists: {}\".format(csvpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: output/gan/history.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: {}\".format(csvpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "discriminator_flatten_input (Inp (None, 28, 28)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gan (Model)                      [(None, 1), (None, 1) 2946577                                      \n",
      "____________________________________________________________________________________________________\n",
      "yfake (Activation)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "yreal (Activation)               (None, 1)             0                                            \n",
      "====================================================================================================\n",
      "Total params: 2,946,577.0\n",
      "Trainable params: 2,946,577.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# gan (x - > yfake, yreal), z generated on GPU\n",
    "gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build adversarial model\n",
    "model = AdversarialModel(base_model=gan,\n",
    "                         player_params=[generator.trainable_weights, discriminator.trainable_weights],\n",
    "                         player_names=[\"generator\", \"discriminator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adversarial_optimizer = AdversarialOptimizerSimultaneous()\n",
    "opt_g = Adam(1e-4, decay=1e-4)\n",
    "opt_d = Adam(1e-3, decay=1e-4)\n",
    "loss = 'binary_crossentropy' # binary classification task: REAL or FAKE. Therefore binary cross entropy loss.\n",
    "\n",
    "model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                          player_optimizers=[opt_g, opt_d],\n",
    "                          loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create callback to generate images\n",
    "zsamples = np.random.normal(size=(10 * 10, latent_dim))\n",
    "\n",
    "def generator_sampler():\n",
    "    return generator.predict(zsamples).reshape((10, 10, 28, 28))\n",
    "\n",
    "generator_cb = ImageGridCallback(os.path.join(\"output/gan\", \"epoch-{:03d}.png\"), generator_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 176s - loss: 18.7926 - generator_loss: 16.3468 - generator_yfake_loss: 3.6518 - generator_yreal_loss: 10.4823 - discriminator_loss: 2.4459 - discriminator_yfake_loss: 0.0850 - discriminator_yreal_loss: 0.1481 - val_loss: 19.5150 - val_generator_loss: 17.0469 - val_generator_yfake_loss: 2.7409 - val_generator_yreal_loss: 12.1702 - val_discriminator_loss: 2.4681 - val_discriminator_yfake_loss: 0.1996 - val_discriminator_yreal_loss: 0.1327\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "# GPU version: https://raw.githubusercontent.com/bstriner/keras-adversarial/master/examples/example_gan.py\n",
    "# of course one epoch is too small. Put at least 100 epochs and if you run on CPU, be patient!\n",
    "# also we have a mode collapse with this simple model:\n",
    "# The generator understands that outputting 1 is the best way to fake the discriminator.\n",
    "# So I guess most of the trainings do not work well because the generated numbers will be almost always 1.\n",
    "nb_epoch = 1 # run all this code on a GPU and it will be much faster! I have 117 seconds on my CPU and 22 seconds on my GPU.\n",
    "xtrain, xtest = mnist_data()\n",
    "y = gan_targets(xtrain.shape[0])\n",
    "ytest = gan_targets(xtest.shape[0])\n",
    "callbacks = [generator_cb]\n",
    "if K.backend() == \"tensorflow\":\n",
    "    callbacks.append(\n",
    "        TensorBoard(log_dir=os.path.join(\"output/gan\", 'logs'), histogram_freq=0, write_graph=True, write_images=True))\n",
    "history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest), callbacks=callbacks, nb_epoch=nb_epoch,\n",
    "              batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save history to CSV\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(csvpath)\n",
    "\n",
    "# save models\n",
    "generator.save(os.path.join(\"output/gan\", \"generator.h5\"))\n",
    "discriminator.save(os.path.join(\"output/gan\", \"discriminator.h5\"))\n",
    "\n",
    "# h5 files can be used to generate pictures later. Only the generator is important here.\n",
    "# We can discard the discriminator because our main purpose is to generate nice pictures.\n",
    "\n",
    "# Code to load a model from h5 files:\n",
    "# from keras.models import load_model\n",
    "# model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12118ca58>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADNVJREFUeJzt3X+oX/V9x/Hn20QNpkUSgzGkbnYaJkUyO6NMkNHBLE6K\nWgSp+EdkpekfFVYYRHF/TBiDMtZK/6qkKI2jSztQMRRZ2umo/WOIiWj8tUanKU28mpoUav2VX+/9\ncU+2q97v+d58f53vve/nAy73+z2f8z3nzeG+7vnxOef7icxEUj1ndF2ApG4Yfqkowy8VZfilogy/\nVJThl4oy/FJRhl8qyvBLRS2f5MoiwtsJpTHLzFjIfEPt+SPiuoj4ZUS8GhF3DbMsSZMVg97bHxHL\ngH3AtcAB4Gng1sx8qeUz7vmlMZvEnv8q4NXMfC0zjwI/Am4cYnmSJmiY8K8Hfj3n/YFm2kdExJaI\n2B0Ru4dYl6QRG/sFv8zcBmwDD/ulaTLMnv8gcOGc959ppklaBIYJ/9PAhoj4bEScBXwF2DmasiSN\n28CH/Zl5PCLuAHYBy4AHMvPFkVUmaawG7uobaGWe80tjN5GbfCQtXoZfKsrwS0UZfqkowy8VZfil\nogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFTXR\nIbqluW6++ebW9p0724eBWLNmTWv7zMzMaddUiXt+qSjDLxVl+KWiDL9UlOGXijL8UlGGXypqqFF6\nI2I/8A5wAjiemZv6zO8ovcVcccUVPdt27drV+tmNGze2tp9zzjmt7a+//nrPthMnTrR+djFb6Ci9\no7jJ5y8y8+0RLEfSBHnYLxU1bPgT+GlE7ImILaMoSNJkDHvYf01mHoyI84GfRcR/Z+aTc2do/in4\nj0GaMkPt+TPzYPP7EPAIcNU882zLzE39LgZKmqyBwx8RKyPi06deA18EXhhVYZLGa5jD/rXAIxFx\najn/mpn/PpKqJI3dwOHPzNeAPxlhLVqCVqxY0bNt5cqVrZ/dunVra/t9993X2r58ee8/76Xcz79Q\ndvVJRRl+qSjDLxVl+KWiDL9UlOGXihrqkd7TXpmP9C45zX0ePb3xxhs92y644IKh1n3ppZe2tu/b\nt69n2yT/7idtoY/0uueXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIcoltDufrqq1vbh+nLf//991vb\n2/rxYWn35Y+Ce36pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsp+frVatWpVa/tjjz02tnXv2bOntd1+\n/OG455eKMvxSUYZfKsrwS0UZfqkowy8VZfilovr280fEA8CXgEOZeVkzbTXwY+AiYD9wS2b+dnxl\nqitHjx5tbT/33HPHtu5+Q3BrOAvZ8/8AuO5j0+4CHs/MDcDjzXtJi0jf8Gfmk8CRj02+EdjevN4O\n3DTiuiSN2aDn/Gszc6Z5/SawdkT1SJqQoe/tz8xsG4MvIrYAW4Zdj6TRGnTP/1ZErANofh/qNWNm\nbsvMTZm5acB1SRqDQcO/E9jcvN4MPDqaciRNSt/wR8QO4L+AP46IAxHxVeBbwLUR8Qrwl817SYtI\nTPKZ6LZrA5pOx44da21fvnzwy0b9/vbOOMN70AaRmbGQ+dy6UlGGXyrK8EtFGX6pKMMvFWX4paL8\n6u7iItp7hY4c+fgzXR91/vnnD7zu2267beDPanju+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKPv5\ni9u6dWtr+zD9+AAnT57s2bZjx46hlq3huOeXijL8UlGGXyrK8EtFGX6pKMMvFWX4paL86u4lbtWq\nVa3thw8fbm3v97x/P1deeWXPtt27dw+1bM3Pr+6W1MrwS0UZfqkowy8VZfilogy/VJThl4rq+zx/\nRDwAfAk4lJmXNdPuAb4G/KaZ7e7MfGxcRWpw5513Xmv7sP347733Xmv73r17h1q+xmche/4fANfN\nM/3ezLy8+TH40iLTN/yZ+STQPmyLpEVnmHP+OyJib0Q8EBHt95BKmjqDhv97wMXA5cAM8O1eM0bE\nlojYHRHeyC1NkYHCn5lvZeaJzDwJfB+4qmXebZm5KTM3DVqkpNEbKPwRsW7O2y8DL4ymHEmTspCu\nvh3AF4A1EXEA+HvgCxFxOZDAfuDrY6xR0hj0DX9m3jrP5PvHUIsGtHHjxp5tzz333FjX/cQTT7S2\nHz16dKzr1+C8w08qyvBLRRl+qSjDLxVl+KWiDL9UlF/dvQTs27evZ9uGDRuGWvaHH37Y2r569erW\n9n6P/Gr0/OpuSa0Mv1SU4ZeKMvxSUYZfKsrwS0UZfqmovo/0qnvLli1rbb/kkkvGtu62ewjAfvzF\nzD2/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxXl8/yLwAcffNDafvbZZw+87H7P669YsWLgZasbPs8v\nqZXhl4oy/FJRhl8qyvBLRRl+qSjDLxXV93n+iLgQeBBYCySwLTO/GxGrgR8DFwH7gVsy87fjK3Xp\nOnz4cGv7WWedNbZ133DDDWNbtqbbQvb8x4G/zczPAX8GfCMiPgfcBTyemRuAx5v3khaJvuHPzJnM\nfKZ5/Q7wMrAeuBHY3sy2HbhpXEVKGr3TOuePiIuAzwNPAWszc6ZpepPZ0wJJi8SCv8MvIj4FPAR8\nMzN/F/H/tw9nZva6bz8itgBbhi1U0mgtaM8fEWcyG/wfZubDzeS3ImJd074OODTfZzNzW2ZuysxN\noyhY0mj0DX/M7uLvB17OzO/MadoJbG5ebwYeHX15ksal7yO9EXEN8AvgeeBkM/luZs/7/w34A+BX\nzHb1HemzrJKP9J555pmt7e++++5Qn29z/Pjx1vZ+3YiTfORbo7HQR3p9nn8CDL8myef5JbUy/FJR\nhl8qyvBLRRl+qSjDLxXlEN0jsHx5+2Zcv379UJ/vp6077t577x34s1ra3PNLRRl+qSjDLxVl+KWi\nDL9UlOGXijL8UlH284/AiRMnWttvv/321va5X4k2iLa++jvvvHOoZWvpcs8vFWX4paIMv1SU4ZeK\nMvxSUYZfKsrwS0X51d0jsGzZstb2M85o/x+7Zs2a1vZjx461tl988cU925566qnWzy5lbfdPLOXv\nMfCruyW1MvxSUYZfKsrwS0UZfqkowy8VZfilovr280fEhcCDwFoggW2Z+d2IuAf4GvCbZta7M/Ox\nPstaup2r0pRYaD//QsK/DliXmc9ExKeBPcBNwC3A7zPznxdalOGXxm+h4e/7TT6ZOQPMNK/fiYiX\ngfYhaCRNvdM654+Ii4DPA6fuGb0jIvZGxAMRsarHZ7ZExO6I2D1UpZJGasH39kfEp4CfA/+YmQ9H\nxFrgbWavA/wDs6cGf91nGR72S2M2snN+gIg4E/gJsCszvzNP+0XATzLzsj7LMfzSmI3swZ6YfTTq\nfuDlucFvLgSe8mXghdMtUlJ3FnK1/xrgF8DzwMlm8t3ArcDlzB727we+3lwcbFuWe35pzEZ62D8q\nhl8aP5/nl9TK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VFTf\nL/AcsbeBX815v6aZNo2mtbZprQusbVCjrO0PFzrjRJ/n/8TKI3Zn5qbOCmgxrbVNa11gbYPqqjYP\n+6WiDL9UVNfh39bx+ttMa23TWhdY26A6qa3Tc35J3el6zy+pI52EPyKui4hfRsSrEXFXFzX0EhH7\nI+L5iHi26yHGmmHQDkXEC3OmrY6In0XEK83veYdJ66i2eyLiYLPtno2I6zuq7cKI+M+IeCkiXoyI\nv2mmd7rtWurqZLtN/LA/IpYB+4BrgQPA08CtmfnSRAvpISL2A5sys/M+4Yj4c+D3wIOnRkOKiH8C\njmTmt5p/nKsy884pqe0eTnPk5jHV1mtk6dvpcNuNcsTrUehiz38V8GpmvpaZR4EfATd2UMfUy8wn\ngSMfm3wjsL15vZ3ZP56J61HbVMjMmcx8pnn9DnBqZOlOt11LXZ3oIvzrgV/PeX+A6RryO4GfRsSe\niNjSdTHzWDtnZKQ3gbVdFjOPviM3T9LHRpaemm03yIjXo+YFv0+6JjP/FPgr4BvN4e1Uytlztmnq\nrvkecDGzw7jNAN/usphmZOmHgG9m5u/mtnW57eapq5Pt1kX4DwIXznn/mWbaVMjMg83vQ8AjzJ6m\nTJO3Tg2S2vw+1HE9/ycz38rME5l5Evg+HW67ZmTph4AfZubDzeTOt918dXW13boI/9PAhoj4bESc\nBXwF2NlBHZ8QESubCzFExErgi0zf6MM7gc3N683Aox3W8hHTMnJzr5Gl6XjbTd2I15k58R/gemav\n+P8P8Hdd1NCjrj8Cnmt+Xuy6NmAHs4eBx5i9NvJV4DzgceAV4D+A1VNU278wO5rzXmaDtq6j2q5h\n9pB+L/Bs83N919uupa5Otpt3+ElFecFPKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJR/wvmyUoY\naTehUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12034c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fake_image_from_generator = generator_sampler()[0][2] # generator_sampler() returns 10x10 images. I chose one randomly (at index 0,2)\n",
    "plt.imshow(fake_image_from_generator, cmap='gray') # looks like a 1!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
