{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering vs Content based items vs hybrid systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "\n",
    "from zipfile import ZipFile\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2 compat\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "\n",
    "ML_100K_URL = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "ML_100K_FILENAME = ML_100K_URL.rsplit('/', 1)[1]\n",
    "ML_100K_FOLDER = 'ml-100k'\n",
    "\n",
    "if not op.exists(ML_100K_FILENAME):\n",
    "    print('Downloading %s to %s...' % (ML_100K_URL, ML_100K_FILENAME))\n",
    "    urlretrieve(ML_100K_URL, ML_100K_FILENAME)\n",
    "\n",
    "if not op.exists(ML_100K_FOLDER):\n",
    "    print('Extracting %s to %s...' % (ML_100K_FILENAME, ML_100K_FOLDER))\n",
    "    ZipFile(ML_100K_FILENAME).extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "From: http://files.grouplens.org/datasets/movielens/ml-100k-README.txt\n",
    "u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.\n",
    "              Each user has rated at least 20 movies.  Users and items are\n",
    "              numbered consecutively from 1.  The data is randomly\n",
    "              ordered. This is a tab separated list of \n",
    "\t         user id | item id | rating | timestamp. \n",
    "              The time stamps are unix seconds since 1/1/1970 UTC   \"\"\"\n",
    "\n",
    "all_ratings = pd.read_csv(op.join(ML_100K_FOLDER, 'u.data'), \n",
    "                          sep='\\t', \n",
    "                          names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "# one line corresponds to one rating per user per movie.\n",
    "\n",
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>url</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name         date        genre  \\\n",
       "1   Toy Story (1995)  01-Jan-1995  01-Jan-1997   \n",
       "2   GoldenEye (1995)  01-Jan-1995  01-Jan-1997   \n",
       "3  Four Rooms (1995)  01-Jan-1995  01-Jan-1997   \n",
       "4  Get Shorty (1995)  01-Jan-1995  01-Jan-1997   \n",
       "5     Copycat (1995)  01-Jan-1995  01-Jan-1997   \n",
       "\n",
       "                                                 url  feat_0  feat_1  feat_2  \\\n",
       "1  http://us.imdb.com/M/title-exact?Toy%20Story%2...       0       0       0   \n",
       "2  http://us.imdb.com/M/title-exact?GoldenEye%20(...       0       1       1   \n",
       "3  http://us.imdb.com/M/title-exact?Four%20Rooms%...       0       0       0   \n",
       "4  http://us.imdb.com/M/title-exact?Get%20Shorty%...       0       1       0   \n",
       "5  http://us.imdb.com/M/title-exact?Copycat%20(1995)       0       0       0   \n",
       "\n",
       "   feat_3  feat_4  feat_5   ...     feat_9  feat_10  feat_11  feat_12  \\\n",
       "1       1       1       1   ...          0        0        0        0   \n",
       "2       0       0       0   ...          0        0        0        0   \n",
       "3       0       0       0   ...          0        0        0        0   \n",
       "4       0       0       1   ...          0        0        0        0   \n",
       "5       0       0       0   ...          0        0        0        0   \n",
       "\n",
       "   feat_13  feat_14  feat_15  feat_16  feat_17  feat_18  \n",
       "1        0        0        0        0        0        0  \n",
       "2        0        0        0        1        0        0  \n",
       "3        0        0        0        1        0        0  \n",
       "4        0        0        0        0        0        0  \n",
       "5        0        0        0        1        0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"name\", \"date\", \"genre\", \"url\"]\n",
    "names += [\"feat_\" + str(x) for x in range(19)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "From: http://files.grouplens.org/datasets/movielens/ml-100k-README.txt\n",
    "u.item     -- Information about the items (movies); this is a tab separated\n",
    "              list of\n",
    "              movie id | movie title | release date | video release date |\n",
    "              IMDb URL | unknown | Action | Adventure | Animation |\n",
    "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\n",
    "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\n",
    "              Thriller | War | Western |\n",
    "              The last 19 fields are the genres, a 1 indicates the movie\n",
    "              is of that genre, a 0 indicates it is not; movies can be in\n",
    "              several genres at once.\n",
    "              The movie ids are the ones used in the u.data data set.\n",
    "\"\"\"\n",
    "\n",
    "items = pd.read_csv(op.join(ML_100K_FOLDER, 'u.item'), sep='|', encoding='latin-1',\n",
    "                    names=names)\n",
    "\n",
    "# some dates are Nan so we set a default value.\n",
    "# it's not important for our study.\n",
    "items.fillna(value=\"01-Jan-1997\", inplace=True) \n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean          3.529860\n",
       "std           1.125674\n",
       "min           1.000000\n",
       "25%           3.000000\n",
       "50%           4.000000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset is a bit skewed towards high ratings. The average is around 3.53 with a standard deviation of 1.12.\n",
    "\n",
    "all_ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "print('Number of users:', len(all_ratings['user_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "print('Number of movies:', len(all_ratings['item_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_user_id = all_ratings['user_id'].max()\n",
    "max_item_id = all_ratings['item_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we split the dataset into a training and a testing set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratings_train, ratings_test = train_test_split(\n",
    "    all_ratings, test_size=0.2, random_state=0)\n",
    "\n",
    "user_id_train = ratings_train['user_id']\n",
    "item_id_train = ratings_train['item_id']\n",
    "rating_train = ratings_train['rating']\n",
    "\n",
    "user_id_test = ratings_test['user_id']\n",
    "item_id_test = ratings_test['item_id']\n",
    "rating_test = ratings_test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000,), (80000,), (80000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 80 000 samples in the training set.\n",
    "user_id_train.shape, item_id_train.shape, rating_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000,), (20000,), (20000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 20 000 samples in the testing set.\n",
    "user_id_test.shape, item_id_test.shape, rating_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Ranking prediction\n",
    "\n",
    "- Based on a pair (user_id, item_id), we want to be able to predict the rating.\n",
    "- An example is: What would the rating John Appleseed (user id = 404) give to Toy Story 3 (item id = 666)? Would it be 3.5? 4.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "- Collaborative filtering does not use the features of the items to predict the rating. It only uses the similarity between the different users to make a prediction.\n",
    "- Let's see what we can get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras headers. Make sure you use the TensorFlow back\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each sample we input the integer identifiers\n",
    "# of a single user and a single item\n",
    "user_id_input = Input(shape=[1], name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "embedding_size = 11 # 2^11 = 2048. So we could index each movie or user with this embedding.\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "# reshape from shape: (batch_size, input_length, embedding_size)\n",
    "# to shape: (batch_size, input_length * embedding_size) which is\n",
    "# equal to shape: (batch_size, embedding_size)\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "# y = merge([user_vecs, item_vecs], mode='dot', output_shape=(1,))\n",
    "y = layers.dot([user_vecs, item_vecs], axes=1)\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input], outputs=[y])\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000,)\n"
     ]
    }
   ],
   "source": [
    "# Useful for debugging the output shape of model\n",
    "initial_train_preds = model.predict([user_id_train, item_id_train]).squeeze()\n",
    "print(initial_train_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.011752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.011778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  80000.000000\n",
       "mean      -0.000013\n",
       "std        0.002803\n",
       "min       -0.011752\n",
       "25%       -0.001894\n",
       "50%       -0.000022\n",
       "75%        0.001863\n",
       "max        0.011778"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to show you how random the score are! Half are negative when scores are defined positive.\n",
    "pd.DataFrame(initial_train_preds).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random init MAE: 3.531\n"
     ]
    }
   ],
   "source": [
    "# Throughout the study we're going to use the MAE error. \n",
    "# It's pretty easy to understand because it's the mean absolute error.\n",
    "# For example, if the true score is 3.5 and we predict 2.1, the error is 3.5 - 2.1 = 1.4\n",
    "# The MSE is a bit harder to understand.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"Random init MAE: %0.3f\" % mean_absolute_error(initial_train_preds, rating_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/20\n",
      "1s - loss: 3.2745 - val_loss: 2.3261\n",
      "Epoch 2/20\n",
      "1s - loss: 1.4207 - val_loss: 1.0231\n",
      "Epoch 3/20\n",
      "1s - loss: 0.8965 - val_loss: 0.8479\n",
      "Epoch 4/20\n",
      "1s - loss: 0.7881 - val_loss: 0.7959\n",
      "Epoch 5/20\n",
      "1s - loss: 0.7490 - val_loss: 0.7752\n",
      "Epoch 6/20\n",
      "1s - loss: 0.7301 - val_loss: 0.7660\n",
      "Epoch 7/20\n",
      "1s - loss: 0.7190 - val_loss: 0.7582\n",
      "Epoch 8/20\n",
      "1s - loss: 0.7114 - val_loss: 0.7551\n",
      "Epoch 9/20\n",
      "1s - loss: 0.7050 - val_loss: 0.7540\n",
      "Epoch 10/20\n",
      "1s - loss: 0.7002 - val_loss: 0.7518\n",
      "Epoch 11/20\n",
      "1s - loss: 0.6964 - val_loss: 0.7492\n",
      "Epoch 12/20\n",
      "1s - loss: 0.6924 - val_loss: 0.7478\n",
      "Epoch 13/20\n",
      "1s - loss: 0.6896 - val_loss: 0.7474\n",
      "Epoch 14/20\n",
      "1s - loss: 0.6865 - val_loss: 0.7473\n",
      "Epoch 15/20\n",
      "1s - loss: 0.6840 - val_loss: 0.7452\n",
      "Epoch 16/20\n",
      "1s - loss: 0.6811 - val_loss: 0.7451\n",
      "Epoch 17/20\n",
      "1s - loss: 0.6786 - val_loss: 0.7439\n",
      "Epoch 18/20\n",
      "1s - loss: 0.6762 - val_loss: 0.7411\n",
      "Epoch 19/20\n",
      "1s - loss: 0.6732 - val_loss: 0.7415\n",
      "Epoch 20/20\n",
      "1s - loss: 0.6707 - val_loss: 0.7415\n"
     ]
    }
   ],
   "source": [
    "# Let's start the training.\n",
    "\n",
    "history = model.fit([user_id_train, item_id_train], rating_train,\n",
    "                    batch_size=64, epochs=20, validation_split=0.1,\n",
    "                    shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train MAE: 0.664\n",
      "Final test MAE: 0.735\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict([user_id_train, item_id_train]).squeeze()\n",
    "print(\"Final train MAE: %0.3f\" % mean_absolute_error(train_preds, rating_train))\n",
    "\n",
    "test_preds = model.predict([user_id_test, item_id_test]).squeeze()\n",
    "print(\"Final test MAE: %0.3f\" % mean_absolute_error(test_preds, rating_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's now consider a bigger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id_input = Input(shape=[1], name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "embedding_size = 11\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "# reshape from shape: (batch_size, input_length, embedding_size)\n",
    "# to shape: (batch_size, input_length * embedding_size) which is\n",
    "# equal to shape: (batch_size, embedding_size)\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "input_vecs = layers.concatenate([user_vecs, item_vecs])\n",
    "## Error 1: Dropout was too high, preventing any training\n",
    "input_vecs = Dropout(0.5)(input_vecs)\n",
    "\n",
    "x = Dense(64, activation='relu')(input_vecs)\n",
    "\n",
    "## Error 2: output dimension was 2 where we predict only 1-d rating\n",
    "## Error 3: tanh activation squashes the outputs between -1 and 1\n",
    "## when we want to predict values between 1 and 5\n",
    "y = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input], outputs=[y])\n",
    "## Error 4: A binary crossentropy loss is only useful for binary\n",
    "## classification, while we are in regression (use mse or mae)\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 1.0474 - val_loss: 0.7646\n",
      "Epoch 2/20\n",
      "2s - loss: 0.7578 - val_loss: 0.7552\n",
      "Epoch 3/20\n",
      "2s - loss: 0.7443 - val_loss: 0.7515\n",
      "Epoch 4/20\n",
      "2s - loss: 0.7368 - val_loss: 0.7490\n",
      "Epoch 5/20\n",
      "2s - loss: 0.7322 - val_loss: 0.7455\n",
      "Epoch 6/20\n",
      "2s - loss: 0.7278 - val_loss: 0.7462\n",
      "Epoch 7/20\n",
      "2s - loss: 0.7239 - val_loss: 0.7454\n",
      "Epoch 8/20\n",
      "2s - loss: 0.7246 - val_loss: 0.7448\n",
      "Epoch 9/20\n",
      "2s - loss: 0.7197 - val_loss: 0.7435\n",
      "Epoch 10/20\n",
      "2s - loss: 0.7177 - val_loss: 0.7458\n",
      "Epoch 11/20\n",
      "2s - loss: 0.7145 - val_loss: 0.7390\n",
      "Epoch 12/20\n",
      "2s - loss: 0.7122 - val_loss: 0.7391\n",
      "Epoch 13/20\n",
      "2s - loss: 0.7121 - val_loss: 0.7438\n",
      "Epoch 14/20\n",
      "2s - loss: 0.7096 - val_loss: 0.7347\n",
      "Epoch 15/20\n",
      "2s - loss: 0.7054 - val_loss: 0.7353\n",
      "Epoch 16/20\n",
      "2s - loss: 0.7047 - val_loss: 0.7294\n",
      "Epoch 17/20\n",
      "2s - loss: 0.7023 - val_loss: 0.7300\n",
      "Epoch 18/20\n",
      "2s - loss: 0.7009 - val_loss: 0.7293\n",
      "Epoch 19/20\n",
      "2s - loss: 0.7015 - val_loss: 0.7316\n",
      "Epoch 20/20\n",
      "2s - loss: 0.6998 - val_loss: 0.7296\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([user_id_train, item_id_train], rating_train,\n",
    "                    batch_size=64, epochs=20, validation_split=0.1,\n",
    "                    shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train MAE: 0.676\n",
      "Final test MAE: 0.716\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict([user_id_train, item_id_train]).squeeze()\n",
    "print(\"Final train MAE: %0.3f\" % mean_absolute_error(train_preds, rating_train))\n",
    "\n",
    "test_preds = model.predict([user_id_test, item_id_test]).squeeze()\n",
    "print(\"Final test MAE: %0.3f\" % mean_absolute_error(test_preds, rating_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Content Based Filtering\n",
    "\n",
    "- Now we're going to use the information of the items to predict the rating. \n",
    "- We forget about the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some pre processing here.\n",
    "\n",
    "# transform the date (string) into an int representing the release year\n",
    "parsed_dates = [int(film_date[-4:])\n",
    "                for film_date in items[\"date\"].tolist()]\n",
    "\n",
    "items['parsed_date'] = pd.Series(parsed_dates, index=items.index)\n",
    "max_date = max(items['parsed_date'])\n",
    "min_date = min(items['parsed_date'])\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "items['scaled_date'] = scale(items['parsed_date'].astype('float64'))\n",
    "item_meta_train = items[\"scaled_date\"][item_id_train]\n",
    "item_meta_test = items[\"scaled_date\"][item_id_test]\n",
    "\n",
    "len(item_meta_train), len(item_meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# For each sample we input the integer identifiers\n",
    "# of a single user and a single item\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "meta_input = Input(shape=[1], name='meta_item')\n",
    "\n",
    "embedding_size = 32\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "input_vecs = layers.concatenate([item_vecs, meta_input])\n",
    "\n",
    "x = Dense(64, activation='relu')(input_vecs)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(input_vecs)\n",
    "y = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input, meta_input], outputs=y)\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 1.0483 - val_loss: 0.8212\n",
      "Epoch 2/20\n",
      "1s - loss: 0.7946 - val_loss: 0.8146\n",
      "Epoch 3/20\n",
      "1s - loss: 0.7850 - val_loss: 0.8115\n",
      "Epoch 4/20\n",
      "1s - loss: 0.7802 - val_loss: 0.8078\n",
      "Epoch 5/20\n",
      "1s - loss: 0.7769 - val_loss: 0.8061\n",
      "Epoch 6/20\n",
      "2s - loss: 0.7748 - val_loss: 0.8087\n",
      "Epoch 7/20\n",
      "2s - loss: 0.7732 - val_loss: 0.8071\n",
      "Epoch 8/20\n",
      "2s - loss: 0.7718 - val_loss: 0.8047\n",
      "Epoch 9/20\n",
      "2s - loss: 0.7707 - val_loss: 0.8055\n",
      "Epoch 10/20\n",
      "2s - loss: 0.7694 - val_loss: 0.8062\n",
      "Epoch 11/20\n",
      "2s - loss: 0.7688 - val_loss: 0.8053\n",
      "Epoch 12/20\n",
      "2s - loss: 0.7676 - val_loss: 0.8045\n",
      "Epoch 13/20\n",
      "2s - loss: 0.7669 - val_loss: 0.8036\n",
      "Epoch 14/20\n",
      "2s - loss: 0.7669 - val_loss: 0.8066\n",
      "Epoch 15/20\n",
      "1s - loss: 0.7661 - val_loss: 0.8030\n",
      "Epoch 16/20\n",
      "2s - loss: 0.7655 - val_loss: 0.8043\n",
      "Epoch 17/20\n",
      "2s - loss: 0.7652 - val_loss: 0.8038\n",
      "Epoch 18/20\n",
      "2s - loss: 0.7651 - val_loss: 0.8043\n",
      "Epoch 19/20\n",
      "2s - loss: 0.7645 - val_loss: 0.8026\n",
      "Epoch 20/20\n",
      "2s - loss: 0.7642 - val_loss: 0.8020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([user_id_train, item_id_train, item_meta_train], rating_train,\n",
    "                    batch_size=64, epochs=20, validation_split=0.1,\n",
    "                    shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train MAE: 0.764\n",
      "Final test MAE: 0.791\n"
     ]
    }
   ],
   "source": [
    "# It does not work well. The error is much higher when the user_id is not here. \n",
    "# It means that the user is important.\n",
    "\n",
    "train_preds = model.predict([user_id_train, item_id_train, item_meta_train]).squeeze()\n",
    "print(\"Final train MAE: %0.3f\" % mean_absolute_error(train_preds, rating_train))\n",
    "\n",
    "test_preds = model.predict([user_id_test, item_id_test, item_meta_test]).squeeze()\n",
    "print(\"Final test MAE: %0.3f\" % mean_absolute_error(test_preds, rating_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Systems\n",
    "\n",
    "- Let's not combine the two: Collaborative Filtering and Content Based Items\n",
    "- And see if it helps improve the loss on the test set, when computing the ratings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id_input = Input(shape=[1], name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "meta_input = Input(shape=[1], name='meta_item')\n",
    "\n",
    "embedding_size = 11\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "# reshape from shape: (batch_size, input_length, embedding_size)\n",
    "# to shape: (batch_size, input_length * embedding_size) which is\n",
    "# equal to shape: (batch_size, embedding_size)\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "input_vecs = layers.concatenate([user_vecs, item_vecs, meta_input])\n",
    "input_vecs = Dropout(0.5)(input_vecs)\n",
    "\n",
    "# Final test MAE: 0.712\n",
    "x = Dense(64, activation='relu')(input_vecs)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "y = Dense(1)(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input, meta_input], outputs=y)\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/20\n",
      "3s - loss: 1.0204 - val_loss: 0.7789\n",
      "Epoch 2/20\n",
      "3s - loss: 0.7934 - val_loss: 0.7671\n",
      "Epoch 3/20\n",
      "3s - loss: 0.7621 - val_loss: 0.7480\n",
      "Epoch 4/20\n",
      "3s - loss: 0.7403 - val_loss: 0.7438\n",
      "Epoch 5/20\n",
      "2s - loss: 0.7294 - val_loss: 0.7463\n",
      "Epoch 6/20\n",
      "3s - loss: 0.7225 - val_loss: 0.7385\n",
      "Epoch 7/20\n",
      "3s - loss: 0.7202 - val_loss: 0.7352\n",
      "Epoch 8/20\n",
      "3s - loss: 0.7152 - val_loss: 0.7410\n",
      "Epoch 9/20\n",
      "3s - loss: 0.7122 - val_loss: 0.7354\n",
      "Epoch 10/20\n",
      "3s - loss: 0.7139 - val_loss: 0.7386\n",
      "Epoch 11/20\n",
      "3s - loss: 0.7093 - val_loss: 0.7342\n",
      "Epoch 12/20\n",
      "3s - loss: 0.7075 - val_loss: 0.7327\n",
      "Epoch 13/20\n",
      "2s - loss: 0.7074 - val_loss: 0.7358\n",
      "Epoch 14/20\n",
      "2s - loss: 0.7082 - val_loss: 0.7329\n",
      "Epoch 15/20\n",
      "3s - loss: 0.7066 - val_loss: 0.7330\n",
      "Epoch 16/20\n",
      "2s - loss: 0.7055 - val_loss: 0.7313\n",
      "Epoch 17/20\n",
      "2s - loss: 0.7026 - val_loss: 0.7302\n",
      "Epoch 18/20\n",
      "3s - loss: 0.7009 - val_loss: 0.7344\n",
      "Epoch 19/20\n",
      "3s - loss: 0.7026 - val_loss: 0.7268\n",
      "Epoch 20/20\n",
      "2s - loss: 0.7002 - val_loss: 0.7333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([user_id_train, item_id_train, item_meta_train], rating_train,\n",
    "                    batch_size=64, epochs=20, validation_split=0.1,\n",
    "                    shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train MAE: 0.682\n",
      "Final test MAE: 0.715\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict([user_id_train, item_id_train, item_meta_train]).squeeze()\n",
    "print(\"Final train MAE: %0.3f\" % mean_absolute_error(train_preds, rating_train))\n",
    "\n",
    "test_preds = model.predict([user_id_test, item_id_test, item_meta_test]).squeeze()\n",
    "print(\"Final test MAE: %0.3f\" % mean_absolute_error(test_preds, rating_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1201748d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1200f2400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# The values you see here are the recorded training_loss, and validation_loss after each epoch.\n",
    "# The first value correspond to the losses after the first epoch.\n",
    "# The convergence is quick.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.legend(['Loss', 'Val Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation\n",
    "\n",
    "- Finally let's see how predicting ratings helps us recommend nice movies to John!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend(user_id, top_n=10):\n",
    "    item_ids = range(1, max_item_id)\n",
    "    seen_movies = list(all_ratings[all_ratings[\"user_id\"] == user_id][\"item_id\"])\n",
    "    item_ids = list(filter(lambda x: x not in seen_movies, item_ids))\n",
    "\n",
    "    print(\"user \" + str(user_id) + \" has seen \" + str(len(seen_movies)) + \" movies. \" +\n",
    "          \"Computing ratings for \" + str(len(item_ids)) + \" other movies\")\n",
    "\n",
    "    item_ids = np.array(item_ids)\n",
    "    user = np.zeros_like(item_ids)\n",
    "    user[:] = user_id\n",
    "    items_meta = items[\"scaled_date\"][item_ids].values\n",
    "\n",
    "    rating_preds = model.predict([user, item_ids, items_meta])\n",
    "\n",
    "    item_ids = np.argsort(rating_preds[:, 0])[::-1].tolist()\n",
    "    rec_items = item_ids[:top_n]\n",
    "    return [(items[\"name\"][movie], rating_preds[movie][0]) for movie in rec_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 404 has seen 44 movies. Computing ratings for 1637 other movies\n",
      "- Miracle on 34th Street (1994) - predicted score: 4.58\n",
      "- Face/Off (1997) - predicted score: 4.57\n",
      "- Assassins (1995) - predicted score: 4.49\n",
      "- Manon of the Spring (Manon des sources) (1986) - predicted score: 4.48\n",
      "- Cold Comfort Farm (1995) - predicted score: 4.47\n",
      "- Jaws 3-D (1983) - predicted score: 4.45\n",
      "- Withnail and I (1987) - predicted score: 4.45\n",
      "- Seven (Se7en) (1995) - predicted score: 4.43\n",
      "- Hoop Dreams (1994) - predicted score: 4.42\n",
      "- Outlaw, The (1943) - predicted score: 4.41\n"
     ]
    }
   ],
   "source": [
    "for recommended_movie in recommend(404):\n",
    "    print('-', recommended_movie[0], '- predicted score:', '%.2f' % recommended_movie[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
